import random
import pandas as pd
import numpy as np

#计算欧式距离
def calcDis(dataSet, centroids, k):
    clalist=[]
    for data in dataSet:
        diff = np.tile(data, (k, 1)) - centroids
        squaredDiff = diff ** 2 
        squaredDist = np.sum(squaredDiff, axis=1)
        distance = squaredDist ** 0.5
        clalist.append(distance) 
    clalist = np.array(clalist)
    return clalist

#计算质心位置
def classify(dataSet, centroids, k):
    #计算样本到质心的欧式距离
    clalist = calcDis(dataSet, centroids, k)
    #重新计算质心
    minDistIndices = np.argmin(clalist, axis=1)
    newCentroids = pd.DataFrame(dataSet).groupby(minDistIndices).mean()
    newCentroids = newCentroids.values
    #计算变化量
    changed = newCentroids - centroids
    return changed, newCentroids

#使用k-means聚类吧
def KM_cluster(dataSet, k):
    #随机取质心
    centroids = random.sample(dataSet, k)
    #更新质心，到收敛为止
    changed, newCentroids = classify(dataSet, centroids, k)
    while np.any(changed != 0):
        changed, newCentroids = classify(dataSet, newCentroids, k)
    centroids = sorted(newCentroids.tolist())
 
    # 根据质心计算每个集群
    cluster = []
    clalist = calcDis(dataSet, centroids, k)
    minDistIndices = np.argmin(clalist, axis=1)  
    for i in range(k):
        cluster.append([])
    for i, j in enumerate(minDistIndices):
        cluster[j].append(dataSet[i])
        
    return centroids, cluster

def kmeans(dataset):
    centroids, cluster = KM_cluster(dataset, 2)
    print('centroid:%s' % centroids)
    print('Clusters:%s' % cluster)

#dataset是这种列表里面塞列表的形式
#dataset=[[1, 1], [1, 2], [2, 1], [6, 4], [6, 3], [5, 4]]
#kmeans(dataset)
